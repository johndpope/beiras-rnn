{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (beiras_aux.py, line 116)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/jota/python/beiras-rnn/beiras_aux.py\"\u001b[0;36m, line \u001b[0;32m116\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from beiras_aux import LoadText,predict_next_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "step_size = 1\n",
    "X,y,chars,chars_to_indices,indices_to_chars=LoadText('Beiras.txt',window_size,step_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras\n",
    "import random\n",
    "\n",
    "# TODO build the required RNN model: a single LSTM hidden layer with softmax activation, categorical_crossentropy loss \n",
    "#Number of unique chars\n",
    "def create_simple_model(chars):\n",
    "    num_chars = len(chars)\n",
    "    model= Sequential()\n",
    "    # 1 Layer .- LSTM layer 1 should be an LSTM module with 200 hidden units\n",
    "    model.add(LSTM(200,input_shape = (window_size,num_chars)))\n",
    "    # 2 Layer .-  Dense, with number chars unit and softmax activation\n",
    "    model.add(Dense(num_chars,activation='softmax'))\n",
    "    # initialize optimizer\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    # compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13559481850202299021, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 28573696\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 16123509706186973612\n",
       " physical_device_desc: \"device: 0, name: GRID K520, pci bus id: 0000:00:03.0\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsmall = X[:10000,:,:]\n",
    "ysmall = y[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[50000,200]\n\t [[Node: lstm_1/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm_1/Reshape_2, lstm_1/strided_slice_1)]]\n\t [[Node: loss/mul/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1396_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'lstm_1/MatMul_1', defined at:\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-4034d054c4e0>\", line 2, in <module>\n    model=create_simple_model(chars)\n  File \"<ipython-input-3-41e6d04afbf6>\", line 15, in create_simple_model\n    model.add(LSTM(200,input_shape = (window_size,num_chars)))\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/models.py\", line 442, in add\n    layer(x)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 268, in __call__\n    return super(Recurrent, self).__call__(inputs, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/engine/topology.py\", line 602, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 340, in call\n    preprocessed_input = self.preprocess_input(inputs, training=None)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 1087, in preprocess_input\n    timesteps, training=training)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 50, in _time_distributed_dense\n    x = K.dot(x, w)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 998, in dot\n    out = tf.matmul(x, y)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50000,200]\n\t [[Node: lstm_1/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm_1/Reshape_2, lstm_1/strided_slice_1)]]\n\t [[Node: loss/mul/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1396_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[50000,200]\n\t [[Node: lstm_1/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm_1/Reshape_2, lstm_1/strided_slice_1)]]\n\t [[Node: loss/mul/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1396_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4034d054c4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_simple_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXsmall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mysmall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# save weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[50000,200]\n\t [[Node: lstm_1/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm_1/Reshape_2, lstm_1/strided_slice_1)]]\n\t [[Node: loss/mul/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1396_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'lstm_1/MatMul_1', defined at:\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-4034d054c4e0>\", line 2, in <module>\n    model=create_simple_model(chars)\n  File \"<ipython-input-3-41e6d04afbf6>\", line 15, in create_simple_model\n    model.add(LSTM(200,input_shape = (window_size,num_chars)))\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/models.py\", line 442, in add\n    layer(x)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 268, in __call__\n    return super(Recurrent, self).__call__(inputs, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/engine/topology.py\", line 602, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 340, in call\n    preprocessed_input = self.preprocess_input(inputs, training=None)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 1087, in preprocess_input\n    timesteps, training=training)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 50, in _time_distributed_dense\n    x = K.dot(x, w)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 998, in dot\n    out = tf.matmul(x, y)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50000,200]\n\t [[Node: lstm_1/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm_1/Reshape_2, lstm_1/strided_slice_1)]]\n\t [[Node: loss/mul/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1396_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# train the model\n",
    "model=create_simple_model(chars)\n",
    "model.fit(Xsmall, ysmall, batch_size=500, epochs=40,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_beiras_small_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1174280/1174280 [==============================] - 749s - loss: 2.1500   \n",
      "Epoch 2/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.8072   \n",
      "Epoch 3/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.6631   \n",
      "Epoch 4/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.5755   \n",
      "Epoch 5/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.5155   \n",
      "Epoch 6/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.4716   \n",
      "Epoch 7/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.4418   \n",
      "Epoch 8/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.4195   \n",
      "Epoch 9/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.3888   \n",
      "Epoch 10/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.4128   \n",
      "Epoch 11/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.4041   \n",
      "Epoch 12/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.3407   \n",
      "Epoch 13/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.3285   \n",
      "Epoch 14/30\n",
      "1174280/1174280 [==============================] - 751s - loss: 1.3178   \n",
      "Epoch 15/30\n",
      "1174280/1174280 [==============================] - 755s - loss: 1.3086   \n",
      "Epoch 16/30\n",
      "1174280/1174280 [==============================] - 755s - loss: 1.3022   \n",
      "Epoch 17/30\n",
      "1174280/1174280 [==============================] - 755s - loss: 1.2916   \n",
      "Epoch 18/30\n",
      "1174280/1174280 [==============================] - 756s - loss: 1.2841   \n",
      "Epoch 19/30\n",
      "1174280/1174280 [==============================] - 755s - loss: 1.2770   \n",
      "Epoch 20/30\n",
      "1174280/1174280 [==============================] - 754s - loss: 1.2711   \n",
      "Epoch 21/30\n",
      "1174280/1174280 [==============================] - 751s - loss: 1.2652   \n",
      "Epoch 22/30\n",
      "1174280/1174280 [==============================] - 751s - loss: 1.2600   \n",
      "Epoch 23/30\n",
      "1174280/1174280 [==============================] - 751s - loss: 1.2549   \n",
      "Epoch 24/30\n",
      "1174280/1174280 [==============================] - 751s - loss: 1.2501   \n",
      "Epoch 25/30\n",
      "1174280/1174280 [==============================] - 750s - loss: 1.2457   \n",
      "Epoch 26/30\n",
      "1174280/1174280 [==============================] - 751s - loss: 1.2415   \n",
      "Epoch 27/30\n",
      "1174280/1174280 [==============================] - 752s - loss: 1.2372   \n",
      "Epoch 28/30\n",
      "1174280/1174280 [==============================] - 752s - loss: 1.2333   \n",
      "Epoch 29/30\n",
      "1174280/1174280 [==============================] - 752s - loss: 1.2298   \n",
      "Epoch 30/30\n",
      "1174280/1174280 [==============================] - 753s - loss: 1.2260   \n"
     ]
    }
   ],
   "source": [
    "# TODO: fit to our larger dataset\n",
    "model=create_simple_model(chars)\n",
    "model.fit(X, y, batch_size=500, nb_epoch=30,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_beiras_large_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=create_simple_model(chars)\n",
    "model.save_weights('model_weights/best_beiras_large_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_complex_model(chars):\n",
    "    num_chars = len(chars)\n",
    "    model= Sequential()\n",
    "    # 1 Layer .- LSTM layer 1 should be an LSTM module with 200 hidden units\n",
    "    model.add(LSTM(200,input_shape = (window_size,num_chars),return_sequences=True))\n",
    "    # 2 Layer .-  Dense, with number chars unit and softmax activation\n",
    "    model.add(LSTM(200))\n",
    "    model.add(Dense(num_chars,activation='softmax'))\n",
    "    # initialize optimizer\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    # compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=2",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-415461e19df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: fit to our larger dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_complex_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-52ea5f1d3ec7>\u001b[0m in \u001b[0;36mcreate_complex_model\u001b[0;34m(chars)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 2 Layer .-  Dense, with number chars unit and softmax activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_chars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# initialize optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    473\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# modify the input spec to include the state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=2"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# TODO: fit to our larger dataset\n",
    "model=create_complex_model(chars)\n",
    "model.summary()\n",
    "print(X.shape)\n",
    "model.fit(X, y, batch_size=500, nb_epoch=30,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_beiras_complex_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
      "\n",
      "predicted chars = \n",
      " con el e máis a sua parte do partido galeguista e a memória de aquil mesmo contro con este senso má\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "poema de rosalía titulado a xusticia pola man e dado á luz no seu libro follas novas por certo que s\"\n",
      "\n",
      "predicted chars = \n",
      "e acaso por ser o que estaban a algúns dos colexios e máis a mariña de anos antes de morte ao pé do \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
      "\n",
      "predicted chars = \n",
      "ñada polo proprio país e a sua propria conciencia social e política- e a construción dun proxecto es\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=create_complex_model(chars)\n",
    "print_predicctions(model,'model_weights/best_beiras_complex_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation,GRU\n",
    "def create_gru_model(chars):\n",
    "    num_chars = len(chars)\n",
    "    model= Sequential()\n",
    "    # 1 Layer .- LSTM layer 1 should be an LSTM module with 200 hidden units\n",
    "    model.add(GRU(200,input_shape = (window_size,num_chars),return_sequences=True))\n",
    "    # 2 Layer .-  Dense, with number chars unit and softmax activation\n",
    "    model.add(GRU(200))\n",
    "    model.add(Dense(num_chars,activation='softmax'))\n",
    "    # initialize optimizer\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    # compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 100, 200)          153600    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 200)               240600    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 55)                11055     \n",
      "=================================================================\n",
      "Total params: 405,255\n",
      "Trainable params: 405,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(1174280, 100, 55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1174280/1174280 [==============================] - 1221s - loss: 1.8849  \n",
      "Epoch 2/30\n",
      "1174280/1174280 [==============================] - 1222s - loss: 1.5179  \n",
      "Epoch 3/30\n",
      "1174280/1174280 [==============================] - 1222s - loss: 1.4071  \n",
      "Epoch 4/30\n",
      "1174280/1174280 [==============================] - 1223s - loss: 1.3475  \n",
      "Epoch 5/30\n",
      "1174280/1174280 [==============================] - 1222s - loss: 1.3076  \n",
      "Epoch 6/30\n",
      "1174280/1174280 [==============================] - 1222s - loss: 1.2778  \n",
      "Epoch 7/30\n",
      "1174280/1174280 [==============================] - 1223s - loss: 1.2535  \n",
      "Epoch 8/30\n",
      "1174280/1174280 [==============================] - 1223s - loss: 1.2331  \n",
      "Epoch 9/30\n",
      "1174280/1174280 [==============================] - 1222s - loss: 1.2152  \n",
      "Epoch 10/30\n",
      "1174280/1174280 [==============================] - 1223s - loss: 1.1999  \n",
      "Epoch 11/30\n",
      "1174280/1174280 [==============================] - 1223s - loss: 1.1863  \n",
      "Epoch 12/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.1741  \n",
      "Epoch 13/30\n",
      "1174280/1174280 [==============================] - 1223s - loss: 1.1634  \n",
      "Epoch 14/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.1531  \n",
      "Epoch 15/30\n",
      "1174280/1174280 [==============================] - 1223s - loss: 1.1440  \n",
      "Epoch 16/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.1357  \n",
      "Epoch 17/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.1281  \n",
      "Epoch 18/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.1212  \n",
      "Epoch 19/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.1148  \n",
      "Epoch 20/30\n",
      "1174280/1174280 [==============================] - 1225s - loss: 1.1088  \n",
      "Epoch 21/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.1036  \n",
      "Epoch 22/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.0980  \n",
      "Epoch 23/30\n",
      "1174280/1174280 [==============================] - 1225s - loss: 1.0935  \n",
      "Epoch 24/30\n",
      "1174280/1174280 [==============================] - 1225s - loss: 1.0888  \n",
      "Epoch 25/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.0850  \n",
      "Epoch 26/30\n",
      "1174280/1174280 [==============================] - 1224s - loss: 1.0805  \n",
      "Epoch 27/30\n",
      "1174280/1174280 [==============================] - 1225s - loss: 1.0772  \n",
      "Epoch 28/30\n",
      "1174280/1174280 [==============================] - 1225s - loss: 1.0735  \n",
      "Epoch 29/30\n",
      "1174280/1174280 [==============================] - 1225s - loss: 1.0705  \n",
      "Epoch 30/30\n",
      "1174280/1174280 [==============================] - 1225s - loss: 1.0673  \n"
     ]
    }
   ],
   "source": [
    "model=create_gru_model(chars)\n",
    "model.summary()\n",
    "print(X.shape)\n",
    "model.fit(X, y, batch_size=500, nb_epoch=30,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_beiras_gru_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
      "\n",
      "predicted chars = \n",
      " un contrasentido arestora e a construción de anos de autonomía galega non é unha concepción do seu \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "poema de rosalía titulado a xusticia pola man e dado á luz no seu libro follas novas por certo que s\"\n",
      "\n",
      "predicted chars = \n",
      "e desenvolve o proceso de descomposición do sistema-mundo as condicións de intervención de capital e\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
      "\n",
      "predicted chars = \n",
      "malo de estado español e o proceso de descomposición do poder constitucional e desembocar nestas ase\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=create_gru_model(chars)\n",
    "print_predicctions(model,'model_weights/best_beiras_gru_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_len=len(X)\n",
    "len_train=int(total_len * 0.9)\n",
    "X_train=X[:len_train]\n",
    "y_train=y[:len_train]\n",
    "X_validate=X[len_train:]\n",
    "y_validate=y[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1056852 samples, validate on 117428 samples\n",
      "Epoch 1/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 2.1634Epoch 00000: val_loss improved from inf to 1.97206, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 723s - loss: 2.1633 - val_loss: 1.9721\n",
      "Epoch 2/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.8114Epoch 00001: val_loss improved from 1.97206 to 1.81125, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 726s - loss: 1.8114 - val_loss: 1.8112\n",
      "Epoch 3/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.6553Epoch 00002: val_loss improved from 1.81125 to 1.72195, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 726s - loss: 1.6554 - val_loss: 1.7219\n",
      "Epoch 4/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.5612Epoch 00003: val_loss improved from 1.72195 to 1.66641, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 727s - loss: 1.5612 - val_loss: 1.6664\n",
      "Epoch 5/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.4525Epoch 00005: val_loss improved from 1.62892 to 1.60768, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 715s - loss: 1.4525 - val_loss: 1.6077\n",
      "Epoch 7/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.4174Epoch 00006: val_loss improved from 1.60768 to 1.58455, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.4174 - val_loss: 1.5846\n",
      "Epoch 8/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.3890Epoch 00007: val_loss improved from 1.58455 to 1.57481, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.3890 - val_loss: 1.5748\n",
      "Epoch 9/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.3658Epoch 00008: val_loss improved from 1.57481 to 1.56436, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.3658 - val_loss: 1.5644\n",
      "Epoch 10/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.3461Epoch 00009: val_loss improved from 1.56436 to 1.55785, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.3462 - val_loss: 1.5578\n",
      "Epoch 11/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.3293Epoch 00010: val_loss improved from 1.55785 to 1.54841, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.3293 - val_loss: 1.5484\n",
      "Epoch 12/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.3144Epoch 00011: val_loss improved from 1.54841 to 1.54534, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.3144 - val_loss: 1.5453\n",
      "Epoch 13/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.3064Epoch 00012: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.3064 - val_loss: 1.5840\n",
      "Epoch 14/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2941Epoch 00013: val_loss improved from 1.54534 to 1.53935, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.2941 - val_loss: 1.5394\n",
      "Epoch 15/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2790Epoch 00014: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 709s - loss: 1.2790 - val_loss: 1.5419\n",
      "Epoch 16/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2694Epoch 00015: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.2694 - val_loss: 1.5463\n",
      "Epoch 17/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2608Epoch 00016: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.2608 - val_loss: 1.5438\n",
      "Epoch 18/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2528Epoch 00017: val_loss improved from 1.53935 to 1.53752, saving model to model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.2527 - val_loss: 1.5375\n",
      "Epoch 19/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2466Epoch 00018: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.2466 - val_loss: 1.5416\n",
      "Epoch 20/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2400Epoch 00019: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.2399 - val_loss: 1.5420\n",
      "Epoch 21/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2330Epoch 00020: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 710s - loss: 1.2330 - val_loss: 1.5475\n",
      "Epoch 22/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2272Epoch 00021: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.2272 - val_loss: 1.5465\n",
      "Epoch 23/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2218Epoch 00022: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.2218 - val_loss: 1.5465\n",
      "Epoch 24/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2160Epoch 00023: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.2160 - val_loss: 1.5494\n",
      "Epoch 25/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2101Epoch 00024: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 712s - loss: 1.2101 - val_loss: 1.5538\n",
      "Epoch 26/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2090Epoch 00025: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.2090 - val_loss: 1.5485\n",
      "Epoch 27/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2033Epoch 00026: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.2033 - val_loss: 1.5502\n",
      "Epoch 28/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1990Epoch 00027: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.1990 - val_loss: 1.5564\n",
      "Epoch 29/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1947Epoch 00028: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.1947 - val_loss: 1.5604\n",
      "Epoch 30/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1909Epoch 00029: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 711s - loss: 1.1909 - val_loss: 1.5626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d7d709400>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "# train the model\n",
    "model=create_simple_model(chars)\n",
    "model.fit(X_train, y_train, batch_size=500, epochs=30,\n",
    "           validation_data=(X_validate, y_validate),\n",
    "          callbacks=[checkpointer],verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
      "\n",
      "predicted chars = \n",
      " a sua constitución estaba a partir de política de castelao e a constitución do colonizador e a cons\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "poema de rosalía titulado a xusticia pola man e dado á luz no seu libro follas novas por certo que s\"\n",
      "\n",
      "predicted chars = \n",
      "e desenvolve a seguida a sua constitución española de compromiso constitucional e a constitución da \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
      "\n",
      "predicted chars = \n",
      "ñada de compromiso constitucional e a constitución da constitución do colonizador e a constitución d\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=create_simple_model(chars)\n",
    "print_predicctions(model,'model_weights/best_beiras_simple_checkpoint_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1056852 samples, validate on 117428 samples\n",
      "Epoch 1/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.9031Epoch 00000: val_loss improved from inf to 1.73509, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1154s - loss: 1.9030 - val_loss: 1.7351\n",
      "Epoch 2/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.5281Epoch 00001: val_loss improved from 1.73509 to 1.59913, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1160s - loss: 1.5281 - val_loss: 1.5991\n",
      "Epoch 3/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.4146Epoch 00002: val_loss improved from 1.59913 to 1.54313, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1162s - loss: 1.4146 - val_loss: 1.5431\n",
      "Epoch 4/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.3534Epoch 00003: val_loss improved from 1.54313 to 1.51628, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1157s - loss: 1.3533 - val_loss: 1.5163\n",
      "Epoch 5/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.3124Epoch 00004: val_loss improved from 1.51628 to 1.50347, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1147s - loss: 1.3124 - val_loss: 1.5035\n",
      "Epoch 6/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2810Epoch 00005: val_loss improved from 1.50347 to 1.48883, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1149s - loss: 1.2810 - val_loss: 1.4888\n",
      "Epoch 7/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2561Epoch 00006: val_loss improved from 1.48883 to 1.48354, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1149s - loss: 1.2561 - val_loss: 1.4835\n",
      "Epoch 8/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2348Epoch 00007: val_loss improved from 1.48354 to 1.48137, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1150s - loss: 1.2348 - val_loss: 1.4814\n",
      "Epoch 9/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2162Epoch 00008: val_loss improved from 1.48137 to 1.47849, saving model to model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5\n",
      "1056852/1056852 [==============================] - 1147s - loss: 1.2162 - val_loss: 1.4785\n",
      "Epoch 10/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.2000Epoch 00009: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1148s - loss: 1.1999 - val_loss: 1.4793\n",
      "Epoch 11/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1853Epoch 00010: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1151s - loss: 1.1854 - val_loss: 1.4854\n",
      "Epoch 12/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1718Epoch 00011: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1151s - loss: 1.1717 - val_loss: 1.4818\n",
      "Epoch 13/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1600Epoch 00012: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1142s - loss: 1.1600 - val_loss: 1.4847\n",
      "Epoch 14/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1493Epoch 00013: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1147s - loss: 1.1493 - val_loss: 1.4872\n",
      "Epoch 15/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1389Epoch 00014: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1147s - loss: 1.1389 - val_loss: 1.4960\n",
      "Epoch 16/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1296Epoch 00015: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1145s - loss: 1.1296 - val_loss: 1.4932\n",
      "Epoch 17/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1204Epoch 00016: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1146s - loss: 1.1204 - val_loss: 1.5034\n",
      "Epoch 18/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1130Epoch 00017: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1147s - loss: 1.1130 - val_loss: 1.5061\n",
      "Epoch 19/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.1053Epoch 00018: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1148s - loss: 1.1053 - val_loss: 1.5155\n",
      "Epoch 20/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0985Epoch 00019: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1149s - loss: 1.0985 - val_loss: 1.5182\n",
      "Epoch 21/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0918Epoch 00020: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1147s - loss: 1.0918 - val_loss: 1.5246\n",
      "Epoch 22/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0863Epoch 00021: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1147s - loss: 1.0863 - val_loss: 1.5300\n",
      "Epoch 23/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0808Epoch 00022: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1148s - loss: 1.0807 - val_loss: 1.5338\n",
      "Epoch 24/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0757Epoch 00023: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1147s - loss: 1.0757 - val_loss: 1.5361\n",
      "Epoch 25/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0708Epoch 00024: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1144s - loss: 1.0708 - val_loss: 1.5425\n",
      "Epoch 26/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0661Epoch 00025: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1153s - loss: 1.0661 - val_loss: 1.5464\n",
      "Epoch 27/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0617Epoch 00026: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1151s - loss: 1.0617 - val_loss: 1.5420\n",
      "Epoch 28/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0580Epoch 00027: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1155s - loss: 1.0580 - val_loss: 1.5504\n",
      "Epoch 29/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0536Epoch 00028: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1154s - loss: 1.0536 - val_loss: 1.5600\n",
      "Epoch 30/30\n",
      "1056500/1056852 [============================>.] - ETA: 0s - loss: 1.0505Epoch 00029: val_loss did not improve\n",
      "1056852/1056852 [==============================] - 1152s - loss: 1.0505 - val_loss: 1.5528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ed032d3c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "# train the model\n",
    "model=create_gru_model(chars)\n",
    "model.fit(X_train, y_train, batch_size=500, epochs=30,\n",
    "           validation_data=(X_validate, y_validate),\n",
    "          callbacks=[checkpointer],verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
      "\n",
      "predicted chars = \n",
      " a sua propria estrutura de constitución e a sua propria estrutura de constitución e a sua propria e\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "poema de rosalía titulado a xusticia pola man e dado á luz no seu libro follas novas por certo que s\"\n",
      "\n",
      "predicted chars = \n",
      "e acabar en contra da sua propria estrutura de constitución e a sua propria estrutura de constitució\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
      "\n",
      "predicted chars = \n",
      "ñada en contra da sua propria estrutura de constitución e a sua propria estrutura de constitución e \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=create_gru_model(chars)\n",
    "print_predicctions(model,'model_weights/best_beiras_gru_checkpoint_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "O checkpoint non mellora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense, Activation,GRU\n",
    "def create_gru_dropout_model(chars):\n",
    "    num_chars = len(chars)\n",
    "    model= Sequential()\n",
    "    # 1 Layer .- LSTM layer 1 should be an LSTM module with 200 hidden units\n",
    "    model.add(GRU(200,input_shape = (window_size,num_chars),return_sequences=True))\n",
    "    # 2 Layer .-  Dense, with number chars unit and softmax activation\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(200))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_chars,activation='softmax'))\n",
    "    # initialize optimizer\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    # compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 100, 200)          153600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 200)               240600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 55)                11055     \n",
      "=================================================================\n",
      "Total params: 405,255\n",
      "Trainable params: 405,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aind2/anaconda3/envs/beiras-rnn/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1174280/1174280 [==============================] - 1264s - loss: 1.9735  \n",
      "Epoch 2/30\n",
      " 458000/1174280 [==========>...................] - ETA: 772s - loss: 1.6839"
     ]
    }
   ],
   "source": [
    "model=create_gru_dropout_model(chars)\n",
    "model.summary()\n",
    "model.fit(X, y, batch_size=500, nb_epoch=30,verbose = 1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_beiras_gru_dropout_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
      "\n",
      "predicted chars = \n",
      " por caso a contradición e de contradición e de contradición e de contradición e de contradición e d\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "poema de rosalía titulado a xusticia pola man e dado á luz no seu libro follas novas por certo que s\"\n",
      "\n",
      "predicted chars = \n",
      "e constitue unha constitución de contradicións de competencia e a construción dos cidadáns do común \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
      "\n",
      "predicted chars = \n",
      "mante en cartas de compostela a construción dos cidadáns do común de competencia e a construción dos\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=create_gru_dropout_model(chars)\n",
    "print_predicctions(model,'model_weights/best_beiras_gru_dropout_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout empeora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:beiras-rnn]",
   "language": "python",
   "name": "conda-env-beiras-rnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
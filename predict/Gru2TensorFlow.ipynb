{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/serving/issues/310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../aux/')\n",
    "from beiras_aux import load_coded_dictionaries, predict_next_chars, clean_text\n",
    "from keras.layers import Dense, Activation, GRU\n",
    "from keras.models import Sequential\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input size of the network, the entry text must have the same length\n",
    "window_size = 100\n",
    "chars_to_indices, indices_to_chars = load_coded_dictionaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import InputLayer\n",
    "def create_gru_model( num_chars):\n",
    "    \"\"\"\n",
    "    Define the network\n",
    "    :param\n",
    "        numbers_chars .- Number chars using in the training process\n",
    "    :return:\n",
    "        model .- Model network defined\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # 1 Layer .- GRU layer 1 should be an GRU module with 200 hidden units\n",
    "    model.add(GRU(200, input_shape=(window_size, num_chars), return_sequences=True))\n",
    "    # 2 Layer .- GRU layer 2 should be an GRU module with 200 hidden units\n",
    "    model.add(GRU(200))\n",
    "    # 2 Layer .-  Dense, with number chars unit and softmax activation\n",
    "    model.add(Dense(num_chars, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "number_chars=len(chars_to_indices)\n",
    "model=create_gru_model(number_chars)\n",
    "model.load_weights('../model_weights/best_beiras_gru_textdata_weights.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def\n",
    "from tensorflow.contrib.session_bundle import exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'../export-tf/1/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "export_path = \"../export-tf/1\"\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "if os.path.isdir(export_path):\n",
    "    shutil.rmtree(export_path)\n",
    "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "signature = predict_signature_def(inputs={'sequence': model.input},\n",
    "                                  outputs={'scores': model.output})\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                         tags=[tag_constants.SERVING],\n",
    "                                         signature_def_map={'predict': signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gru_1_input:0\", shape=(?, 100, 55), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/Softmax:0\", shape=(?, 55), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Prerequisitos installas tennsoflow servein\n",
    "echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list\n",
    "\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
    "\n",
    "sudo apt-get update && sudo apt-get install tensorflow-model-server\n",
    "\n",
    "\n",
    "Dentro do directorio ..export-tf vamos crear un directorio por cada version co formato 1,2,3\n",
    "\n",
    "\n",
    "tensorflow_model_server --port=9000 --model_name=mnist --model_base_path=/tmp/mnist_model/\n",
    "\n",
    "A version tensorflow_model_server que se instala co apt non ten soporte gpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/avloss/01e43d208fbdb2c5b4f9b50e71617cc8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow_model_server --port=9000 --model_name=default --model_base_path=/home/aind2/beiras-rnn/export-tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../aux/')\n",
    "from beiras_aux import load_coded_dictionaries, predict_next_chars, clean_text\n",
    "\n",
    "\n",
    "input_init=\"se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
    "input_init=\"pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
    "\n",
    "window_size = 100\n",
    "chars_to_indices, indices_to_chars = load_coded_dictionaries()\n",
    "number_chars=len(chars_to_indices)\n",
    "input_clean=clean_text(input_init.lower())\n",
    "if len(input_clean) < window_size:\n",
    "    print(\"Sentence must have \", window_size, len(input_sentence))\n",
    "else:\n",
    "    input_clean = input_clean[:window_size]\n",
    "    x_test = np.zeros((1,window_size, number_chars))\n",
    "    for t, char in enumerate(input_clean):\n",
    "        x_test[0, t, chars_to_indices[char]] = 1.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O file pb describe o modelo\n",
    "Si cambio a builder.save(astext=True) xera o pb en modo texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/towards-data-science/how-to-deploy-machine-learning-models-with-tensorflow-part-2-containerize-it-db0ad7ca35a7\n",
    "\n",
    "git clone --recurse-submodules https://github.com/tensorflow/serving.git\n",
    "\n",
    "cd <tensorflow serving source folder>\n",
    "# 2\n",
    "mv ./tensorflow ./tensorflow_\n",
    "mv ./tensorflow_/tensorflow .\n",
    "# 3\n",
    "python -m grpc.tools.protoc ./tensorflow_serving/apis/*.proto --python_out=<path to GAN project> --grpc_python_out=<path to GAN project> --proto_path=.\n",
    "# 4\n",
    "mv ./tensorflow ./tensorflow_\n",
    "mv ./tensorflow_ ./tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "import tensorflow as tf\n",
    "import grpc\n",
    "\n",
    "channel = grpc.insecure_channel(\"localhost:\" + str(9000))\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "request = predict_pb2.PredictRequest() \n",
    "request.model_spec.name = 'default' \n",
    "request.model_spec.signature_name = 'predict' \n",
    "\n",
    "request.inputs['inputs'].CopyFrom( \n",
    "        tf.contrib.util.make_tensor_proto(\n",
    "            x_test,dtype='float32'))\n",
    "result=stub.Predict(request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict=np.array(result.outputs['outputs'].float_val)\n",
    "r = np.argmax(test_predict)  # predict class of each test input\n",
    "d = indices_to_chars[r]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_one(text_predict,stub,window_size,number_chars):\n",
    "    #print(text_predict)\n",
    "    x_test = np.zeros((1,window_size, number_chars))\n",
    "    for t, char in enumerate(text_predict):\n",
    "        x_test[0, t, chars_to_indices[char]] = 1.\n",
    "    request = predict_pb2.PredictRequest() \n",
    "    request.model_spec.name = 'default' \n",
    "    request.model_spec.signature_name = 'predict' \n",
    "    request.inputs['inputs'].CopyFrom( \n",
    "        tf.contrib.util.make_tensor_proto(\n",
    "            x_test,dtype='float32'))\n",
    "    result=stub.Predict(request)\n",
    "    test_predict=np.array(result.outputs['outputs'].float_val)\n",
    "    r = np.argmax(test_predict)  # predict class of each test input\n",
    "    return (indices_to_chars[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\n",
      "m\n"
     ]
    }
   ],
   "source": [
    "input_init=\"se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
    "window_size = 100\n",
    "chars_to_indices, indices_to_chars = load_coded_dictionaries()\n",
    "number_chars=len(chars_to_indices)\n",
    "input_clean=clean_text(input_init.lower())\n",
    "channel = grpc.insecure_channel(\"localhost:\" + str(9000))\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "d=predict_one(input_clean,stub,window_size,number_chars)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_window(text_predict,number_predict,window_size):\n",
    "    chars_to_indices, indices_to_chars = load_coded_dictionaries()\n",
    "    number_chars=len(chars_to_indices)\n",
    "    input_clean=clean_text(text_predict.lower())\n",
    "    channel = grpc.insecure_channel(\"localhost:\" + str(9000))\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    for i in range(number_predict):\n",
    "        d=predict_one(input_clean[i:],stub,window_size,number_chars)\n",
    "        input_clean+=d\n",
    "    return input_clean\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beiras_said=\"pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
    "#beiras_said=\"se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
    "\n",
    "text=predict_window(beiras_said,window_size,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran un contrasentido arestora e a construción de anos de autonomía galega non é unha concepción do seu '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:beiras-rnn]",
   "language": "python",
   "name": "conda-env-beiras-rnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloud.google.com/ml-engine/docs/command-line\n",
    "Create a project and enable it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apt-get install sudo curl and install gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu\n",
    "# Create an environment variable for the correct distribution\n",
    "export CLOUD_SDK_REPO=\"cloud-sdk-$(lsb_release -c -s)\"\n",
    "\n",
    "# Add the Cloud SDK distribution URI as a package source\n",
    "echo \"deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n",
    "\n",
    "# Import the Google Cloud Platform public key\n",
    "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "\n",
    "# Update the package list and install the Cloud SDK\n",
    "sudo apt-get update && sudo apt-get install google-cloud-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init gcloud ans set project and authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gcloud init\n",
    "cloud auth application-default login\n",
    "gcloud config set project ai-ml-dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://cloud.google.com/ml-engine/docs/getting-started-training-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export ml,  Model validation failed: Serving metagraph must contain exactly one SignatureDef with key: serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gru_1_input:0\", shape=(?, 100, 55), dtype=float32)\n",
      "Tensor(\"dense_1/Softmax:0\", shape=(?, 55), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Input and output shape\n",
    "print(model.input)\n",
    "print(model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Make bucket, upload model and depoy\n",
    "MODEL_NAME=BeirasRnn\n",
    "gcloud ml-engine models create $MODEL_NAME --enable-logging\n",
    "gsutil mb gs://beiras_rnn/\n",
    "    \n",
    "    \n",
    "gsutil cp -r ./export-tf/2 gs://beiras_rnn/export-google-ml/7\n",
    "MODEL_NAME=BeirasRnn\n",
    "DEPLOYMENT_SOURCE=\"gs://beiras_rnn/export-google-ml/7\"\n",
    "gcloud ml-engine versions create \"v07\" --model $MODEL_NAME  --origin $DEPLOYMENT_SOURCE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Install google api lib for python\n",
    "pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict from ml\n",
    "the input shape musth hava a shape (number_chars,window_size), i do not now why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.02791549e-03   1.82074245e-13   1.66169353e-04   7.92613406e-08\n",
      "   5.73130601e-05   1.31240768e-05   2.25630544e-07   1.25827592e-05\n",
      "   3.36391054e-06   2.49683217e-06   2.67709061e-06   2.58707291e-06\n",
      "   3.85522708e-06   1.68106453e-06   9.78884920e-02   7.72795000e-04\n",
      "   1.28873562e-05   6.51064329e-05   4.04933803e-02   5.68993273e-05\n",
      "   7.88223770e-05   2.52500555e-04   7.03036606e-01   2.65130211e-06\n",
      "   2.58586806e-05   6.67042732e-02   1.81544849e-04   4.20611771e-03\n",
      "   6.22344902e-03   1.42863850e-04   1.35668085e-06   8.01028404e-03\n",
      "   6.67816699e-02   1.40305041e-04   2.27522425e-04   2.22166782e-05\n",
      "   3.05614267e-05   1.81408183e-07   9.27245637e-05   1.32501589e-06\n",
      "   1.63243293e-13   1.66929716e-13   1.00698369e-03   2.05680620e-13\n",
      "   6.43400635e-05   1.30786441e-13   1.48362204e-04   1.64503529e-13\n",
      "   2.37581412e-06   1.64584519e-13   1.40918200e-05   1.60686067e-13\n",
      "   1.50571059e-05   8.69439134e-07   1.57377144e-06]\n",
      "22 i\n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../aux/')\n",
    "from beiras_aux import load_coded_dictionaries, predict_next_chars, clean_text\n",
    "\n",
    "\n",
    "input_init=\"se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
    "#input_init=\"pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
    "# Load values\n",
    "window_size = 100\n",
    "chars_to_indices, indices_to_chars = load_coded_dictionaries()\n",
    "number_chars=len(chars_to_indices)\n",
    "# Clean the text\n",
    "input_clean=clean_text(input_init.lower())\n",
    "input_clean = input_clean[:window_size]\n",
    "# Text to array [1,input_lenght,num_chars]\n",
    "#x_test = np.zeros((1,window_size, number_chars))\n",
    "#for t, char in enumerate(input_clean):\n",
    "#    x_test[0, t, chars_to_indices[char]] = 1.\n",
    "#x_test   \n",
    "x_test = np.zeros((number_chars,window_size))\n",
    "for t, char in enumerate(input_clean):\n",
    "    x_test[ chars_to_indices[char],t] = 1.\n",
    "    \n",
    "project=\"ai-ml-dl\"\n",
    "model=\"BeirasRnn\"\n",
    "version=\"v07\"\n",
    "service = googleapiclient.discovery.build('ml', 'v1')\n",
    "name = 'projects/{}/models/{}'.format(project, model)\n",
    "if version is not None:\n",
    "        name += '/versions/{}'.format(version)\n",
    "instances={'sequence':x_test.tolist()}\n",
    "response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "test_predict=np.array(response['predictions'][0]['scores'])\n",
    "r = np.argmax(test_predict)  # predict class of each test input\n",
    "print(test_predict)\n",
    "print(r,indices_to_chars[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict from console, return a score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the file\n",
    "import json\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(instances, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gcloud ml-engine predict --model=BeirasRnn --json-instances=data.json --version=v07\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict with funcions, fail\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function\n",
    "def predict_one(text_predict,service,model_name,window_size,chars_to_indices, indices_to_chars):\n",
    "    # Convert input sequence to array\n",
    "    number_chars=len(chars_to_indices)\n",
    "    x_test = np.zeros((number_chars,window_size))\n",
    "    for t, char in enumerate(text_predict):\n",
    "        x_test[chars_to_indices[char],t] = 1.\n",
    "    #Prepare the request\n",
    "    instances={'sequence':x_test.tolist()}\n",
    "    response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "    test_predict=np.array(response['predictions'][0]['scores'])\n",
    "    r = np.argmax(test_predict)  # predict class of each test input\n",
    "    return (indices_to_chars[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Complete a sequence using the server\n",
    "def predict_window(text_predict,number_predict,window_size,lproject,lmodel,lversion):\n",
    "    \n",
    "    # Get dictionaries\n",
    "    chars_to_indices, indices_to_chars = load_coded_dictionaries()\n",
    "    # Clean the test\n",
    "    input_clean=clean_text(text_predict.lower())\n",
    "    # Get stub\n",
    "    service = googleapiclient.discovery.build('ml', 'v1')\n",
    "    name = 'projects/{}/models/{}'.format(lproject, lmodel)\n",
    "    if lversion is not None:\n",
    "        name += '/versions/{}'.format(lversion)\n",
    "    print(name)\n",
    "    # Call server for all charazters\n",
    "    for i in range(number_predict):\n",
    "        d=predict_one(input_clean[i:],service,name,window_size,chars_to_indices, indices_to_chars)\n",
    "        input_clean+=d\n",
    "    return input_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/ai-ml-dl/models/BeirasRnn/versions/v07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcui  ie   eil  hllns e'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "project=\"ai-ml-dl\"\n",
    "model=\"BeirasRnn\"\n",
    "version=\"v07\"\n",
    "\n",
    "input_init=\"se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
    "#input_init=\"pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
    "\n",
    "window_size = 100\n",
    "number_predict=20\n",
    "      \n",
    "\n",
    "response=predict_window(input_init[:window_size],number_predict,\n",
    "                        window_size,project,model,version)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

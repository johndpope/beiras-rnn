{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict one charazter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../aux/')\n",
    "from beiras_aux import load_coded_dictionaries, predict_next_chars, clean_text\n",
    "\n",
    "\n",
    "input_init=\"se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
    "#input_init=\"pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
    "# Load values\n",
    "window_size = 100\n",
    "chars_to_indices, indices_to_chars = load_coded_dictionaries()\n",
    "number_chars=len(chars_to_indices)\n",
    "# Clean the text\n",
    "input_clean=clean_text(input_init.lower())\n",
    "input_clean = input_clean[:window_size]\n",
    "# Text to array [1,input_lenght,num_chars]\n",
    "x_test = np.zeros((window_size, number_chars))\n",
    "for t, char in enumerate(input_clean):\n",
    "    if char in chars_to_indices:\n",
    "        x_test[ t, chars_to_indices[char]] = 1.\n",
    "#x_test   \n",
    "#x_test = np.zeros((number_chars,window_size))\n",
    "#for t, char in enumerate(input_clean):\n",
    "#    if char in chars_to_indices:\n",
    "#        x_test[ chars_to_indices[char],t] = 1.\n",
    "print(len(x_test[0]))    \n",
    "project=\"ai-ml-dl\"\n",
    "model=\"BeirasRnn\"\n",
    "version=\"v10\"\n",
    "service = googleapiclient.discovery.build('ml', 'v1')\n",
    "name = 'projects/{}/models/{}'.format(project, model)\n",
    "if version is not None:\n",
    "        name += '/versions/{}'.format(version)\n",
    "instances={'sequence':x_test.tolist()}\n",
    "response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "test_predict=np.array(response['predictions'][0]['scores'])\n",
    "r = np.argmax(test_predict)  # predict class of each test input\n",
    "print(test_predict)\n",
    "print(r,indices_to_chars[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict sentece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function\n",
    "def predict_one(text_predict,service,model_name,window_size,chars_to_indices, indices_to_chars):\n",
    "    # Convert input sequence to array\n",
    "    number_chars=len(chars_to_indices)\n",
    "    x_test = np.zeros((window_size,number_chars))\n",
    "    for t, char in enumerate(text_predict):\n",
    "       x_test[t,chars_to_indices[char]] = 1.\n",
    "    #print(x_test.shape)\n",
    "    x_test=x_test[:window_size,:]\n",
    "    #Prepare the request\n",
    "    instances={'sequence':x_test.tolist()}\n",
    "    response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "    test_predict=np.array(response['predictions'][0]['scores'])\n",
    "    r = np.argmax(test_predict)  # predict class of each test input\n",
    "    return (indices_to_chars[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete a sequence using the server\n",
    "def predict_window(text_predict,number_predict,window_size,lproject,lmodel,lversion):\n",
    "    \n",
    "    # Get dictionaries\n",
    "    chars_to_indices, indices_to_chars = load_coded_dictionaries()\n",
    "    # Clean the test\n",
    "    input_clean=clean_text(text_predict.lower())\n",
    "    # Get stub\n",
    "    service = googleapiclient.discovery.build('ml', 'v1')\n",
    "    name = 'projects/{}/models/{}'.format(lproject, lmodel)\n",
    "    if lversion is not None:\n",
    "        name += '/versions/{}'.format(lversion)\n",
    "    print(name)\n",
    "    # Call server for all charazters\n",
    "    for i in range(number_predict):\n",
    "        d=predict_one(input_clean[i:],service,name,window_size,chars_to_indices, indices_to_chars)\n",
    "        input_clean+=d\n",
    "    return input_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/ai-ml-dl/models/BeirasRnn/versions/v10\n",
      "se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcumalo de estado español e o proceso de descomposición do poder constitucional e desembocar nestas asembleas a unha concepción do sistema de estado e o proceso de descomposición do sistema-mundo as cond\n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "project=\"ai-ml-dl\"\n",
    "model=\"BeirasRnn\"\n",
    "version=\"v10\"\n",
    "\n",
    "input_init=u\"se moito cando dixen eu que as suas políticas agresoras do común cidadán matan e a sua cospedal alcu\"\n",
    "#input_init=\"pla panfletaria contra as leoninas taxas impostas polo ministro de xustiza actual malia que vulneran\"\n",
    "\n",
    "window_size = 100\n",
    "number_predict=200\n",
    "      \n",
    "\n",
    "response=predict_window(input_init[:window_size],number_predict,\n",
    "                        window_size,project,model,version)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our original text has 1213561 characters\n"
     ]
    }
   ],
   "source": [
    "# read in the text, transforming everything to lower case\n",
    "text_org = open('Beiras.txt', encoding=\"utf-8\").read().lower()\n",
    "print('our original text has ' + str(len(text_org)) + ' characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text_without_source=\"\";\n",
    "regexp=re.compile(r'http')\n",
    "for line in text_org.splitlines():\n",
    "    if not regexp.search(line):\n",
    "        text_without_source= text_without_source + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '¨', 'ª', '«', '\\xad', '´', 'º', '»', '¿', 'à', 'á', 'â', 'ã', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ú', 'ü', '–', '—', '‘', '’', '“', '”', '•', '…']\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(list(set(text_without_source)))\n",
    "print(chars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '$', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¨', '\\xad', 'á', 'ã', 'é', 'ë', 'í', 'î', 'ñ', 'ò', 'ó', 'õ', 'ú', '–', '—']\n",
      "this corpus has 1174380 total number of characters\n",
      "this corpus has 55 unique characters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_clean = re.sub('[ºªàâäçèêïìôöü&%@•…«»”“*/!\"(),.:;_¿¡¿‘’´\\[\\]\\']',' ',text_without_source)\n",
    "text_clean = text_clean.replace(\"  \",\" \")\n",
    "chars=sorted(list(set(text_clean )))\n",
    "print(chars);\n",
    "print (\"this corpus has \" +  str(len(text_clean)) + \" total number of characters\")\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_transform_text(text,window_size,step_size):\n",
    "    # containers for input/output pairs\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    #Number of windows to create\n",
    "    n_windows=int((len(text) - window_size)/ step_size)\n",
    "    for j in range(n_windows) :\n",
    "        # k .- Start index\n",
    "        k= j * step_size\n",
    "        inputs.append(text[k:(k+window_size)])\n",
    "        outputs.append(text[k+window_size])\n",
    "\n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run your text window-ing function \n",
    "window_size = 100\n",
    "step_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this dictionary is a function mapping each unique character to a unique integer\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "\n",
    "# this dictionary is a function mapping each unique integer back to a unique character\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform character-based input/output into equivalent numerical versions\n",
    "def encode_io_pairs(text,window_size,step_size):\n",
    "    # number of unique chars\n",
    "    chars = sorted(list(set(text)))\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and tranform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        y[i, chars_to_indices[outputs[i]]] = 1\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use your function\n",
    "X,y = encode_io_pairs(text_clean,window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15587238462670927579, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3879469056\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 17891074825725798988\n",
       " physical_device_desc: \"device: 0, name: GRID K520, pci bus id: 0000:00:03.0\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsmall = X[:10000,:,:]\n",
    "ysmall = y[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Concatenate,concatenate,Reshape\n",
    "\n",
    "def create_gan_simple_model(chars,shp):\n",
    "    num_chars = len(chars)\n",
    "    opt = Adam(lr=1e-4)\n",
    "    dopt = Adam(lr=1e-3)\n",
    "    \n",
    "    g_input = Input(shape=shp)\n",
    "    H=GRU(200)(g_input)\n",
    "    g_V=Dense(num_chars,activation='softmax')(H)\n",
    "    generator = Model(g_input,g_V)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    generator.summary()\n",
    "    \n",
    "    shp_discriminator=(shp[0]+1,shp[1])\n",
    "    print(shp_discriminator)\n",
    "    d_input = Input(shape=shp_discriminator)\n",
    "    H=GRU(200)(d_input)\n",
    "    d_V=Dense(2,activation='softmax')(H)\n",
    "    discriminator = Model(d_input,d_V)\n",
    "    discriminator.compile(loss='categorical_crossentropy', optimizer=dopt)\n",
    "    discriminator.summary()\n",
    "        \n",
    "    make_trainable(discriminator, False)\n",
    "    \n",
    "    gan_input = Input(shape=shp)\n",
    "    H = generator(gan_input)\n",
    "    print(gan_input.shape,H.shape)\n",
    "    print(H.shape[1],num_chars)\n",
    "    H = Reshape((1,num_chars))(H)\n",
    "    print(gan_input.shape,H.shape)\n",
    "    H=concatenate([gan_input,H],axis=1)\n",
    "    print(H.shape)\n",
    "    gan_V = discriminator(H)\n",
    "    GAN = Model(gan_input, gan_V)\n",
    "    GAN.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "    GAN.summary()\n",
    "    \n",
    "    return generator,discriminator,GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 55)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 200)               153600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 55)                11055     \n",
      "=================================================================\n",
      "Total params: 164,655\n",
      "Trainable params: 164,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(101, 55)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 101, 55)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 200)               153600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 154,002\n",
      "Trainable params: 154,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(?, 100, 55) (?, 55)\n",
      "55 55\n",
      "(?, 100, 55) (?, 1, 55)\n",
      "(?, 101, 55)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 100, 55)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 55)            164655      input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 1, 55)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 101, 55)       0           input_3[0][0]                    \n",
      "                                                                   reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 2)             154002      concatenate_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 318,657\n",
      "Trainable params: 164,655\n",
      "Non-trainable params: 154,002\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generetor,discriminator,GAN=create_gan_simple_model(chars,X.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:beiras-rnn]",
   "language": "python",
   "name": "conda-env-beiras-rnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
